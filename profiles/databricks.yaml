# FIXME::REQUIRED: set an MLflow experiment name to track recipe executions and artifacts. On Databricks, an
#                  experiment name must be a valid path in the workspace.
#
experiment:
  name: "/Users/yinxi.zhang@databricks.com/recipe-demo-experiment"

model_registry:
# FIXME::OPTIONAL: Set the registry server URI, useful if you have a registry server different
#                  from the tracking server. First create a Databricks Profile, see
#                  https://github.com/databricks/databricks-cli#installation
#   uri: "databricks://DATABRICKS_PROFILE_NAME"
# FIXME::REQUIRED: Specifies the name of the Registered Model to use when registering a trained
#                  model to the MLflow Model Registry.
  model_name: "yz-recipe-model"

INGEST_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#ingest-step
  # FIXME::REQUIRED: Specify the format of the training and evaluation dataset. Natively supported
  #                  formats are: parquet, spark_sql, delta.
  using: "delta"
  location: "dbfs:/tmp/yz/recipe_ingest_data"
  #location: "yz.recipe_ingest_data"
  # FIXME::OPTIONAL: Specify the training and evaluation data location. This is usually a DBFS
  # location ("dbfs:/...") or a SQL table ("SCHEMA.TABLE").
  #using: spark_sql
  #sql: "SELECT * except (date) FROM yz.recipe_ingest_data"
  skip_data_profiling: true # disable data profiling due to dateType col
  
SPLIT_CONFIG:
  using: custom
  split_method: custom_split
  # OPTIONAL: post split filter method - the method will be called by train, val and test datasets
  # post_split_filter_method: create_dataset_filter
  skip_data_profiling: true  # disable data profiling due to dateType col
  
TRAIN_CONFIG:
  #using: automl/flaml
  #time_budget_secs: 180
  using: custom
  estimator_method: estimator_fn
  tuning:
    enabled: True
    algorithm: "hyperopt.tpe.suggest"
    max_trials: 8
    #early_stop_fn: my_early_stop_fn
    parallelism: 1
    sample_fraction: 0.5
    parameters:
      max_depth:
        distribution: "quniform"
        low: 3.0
        high: 6.0
        q: 1.
      max_features:
        values: ["sqrt", "log2", None]
  skip_data_profiling: true
# INGEST_SCORING_CONFIG:
#   For different options please read: https://github.com/mlflow/recipes-regression-template#batch-scoring
#   FIXME::OPTIONAL: Specify the format of the scoring dataset. Natively supported formats are:
#                    parquet, spark_sql, delta.
#   using: ""
#   FIXME::OPTIONAL: Specify the scoring data location.
#   location: ""

# PREDICT_OUTPUT_CONFIG:
#   For different options please read: https://github.com/mlflow/recipes-regression-template#predict-step
#   FIXME::OPTIONAL: Specify the format of the scored dataset. Natively supported formats are:
#                    parquet, delta, table.
#   using: ""
#   FIXME::OPTIONAL: Specify the output location of the batch scoring predict step.
#   location: ""
